{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all imports for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:\\GitHub\\Flower_Classifier_Project\\flower_data\n",
    "# D:\\GitHub\\Flower_Classifier_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from datetime import datetime as dt\n",
    "import pickle\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--save_dir SAVE_DIR] [--arch ARCH]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--hidden_units HIDDEN_UNITS] [--epochs EPOCHS]\n",
      "                             [--device DEVICE]\n",
      "                             [data_dir]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('data_dir', metavar='data_dir', type=str, nargs='?',\n",
    "                    help='This is the root directory of the images.')\n",
    "\n",
    "parser.add_argument('--save_dir', action='store',\n",
    "                    dest='save_dir',\n",
    "                    help='this is the path where the checkpoint.pth file will be located.')\n",
    "\n",
    "parser.add_argument('--arch', action='store', type=str,\n",
    "                    dest='arch',\n",
    "                    help='Provide the architecture of the model vgg19_bn or densenet121.')\n",
    "\n",
    "parser.add_argument('--learning_rate', action='store', type=float,\n",
    "                    dest='learning_rate',\n",
    "                    help='Provide the learning rate of the model in decimal points.')\n",
    "\n",
    "parser.add_argument('--hidden_units', action='store', type=str,\n",
    "                    dest='hidden_units',\n",
    "                    help='Provide the hidden units of the model 500,300,etc. --no space')\n",
    "\n",
    "parser.add_argument('--epochs', action='store', type=int,\n",
    "                    dest='epochs',\n",
    "                    help='Provide the epochs of the training as an int.')\n",
    "\n",
    "parser.add_argument('--device', action='store', type=str,\n",
    "                    dest='device',\n",
    "                    help='Provide the device cuda or cpu in which the model will train.')\n",
    "\n",
    "results = parser.parse_args()\n",
    "\n",
    "if results.hidden_units:\n",
    "    results.hidden_units = [int(x) for x in results.hidden_units.split(',')]\n",
    "\n",
    "print('\\nCommand line selections:')\n",
    "print('Data Directory = {!r}'.format(results.data_dir))\n",
    "print('Checkpoint save_dir = {!r}'.format(results.save_dir))\n",
    "print('Architecture = {!r}'.format(results.arch))\n",
    "print('Learning Rate = {!r}'.format(results.learning_rate))\n",
    "print('Hidden Units = {!r}'.format(results.hidden_units))\n",
    "print('Epochs = {!r}'.format(results.epochs))\n",
    "print('Device = {!r}'.format(results.device))\n",
    "print('-')\n",
    "\n",
    "'''print('Command line warnings:')\n",
    "if results.image_path == None: print('No image parsed. You will have the chance to select an image as an input.')\n",
    "if results.checkpoint_name == None: print('No checkpoint name given. The default cehckpoint.pth will be used. ')\n",
    "if results.cat_to_name == None: print('No --cat parsed. You will have the chance to input categories later.')\n",
    "if results.topk == None: print('No --topk parsed. You will have the chance to input the top k later.')\n",
    "if results.device == None: print('No --device parsed. You will have the chance to input the device later.')\n",
    "print('-')'''\n",
    "\n",
    "# command line checks\n",
    "print('Command line warnings:')\n",
    "if results.device not in ('cuda', 'cpu', None):\n",
    "    results.device = None\n",
    "    print('Wrong device input. Please use the command input to select desired device.')\n",
    "if results.arch not in ('vgg19_bn', 'densenet121', None):\n",
    "    results.arch = None\n",
    "    print('Wrong model architecture. Please use the command input to select desired architecture.')\n",
    "if type(results.hidden_units) != list and results.hidden_units != None:\n",
    "    results.hidden_units = None\n",
    "    print('Wrong hidden units format. Please use the command input the hidden units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preping data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class results: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Model data folders:\n",
      "    Using root path: \tD:\\GitHub\\Flower_Classifier_Project\\flower_data\n",
      "    Using train path: \tD:\\GitHub\\Flower_Classifier_Project\\flower_data\\train\n",
      "    Using valid path: \tD:\\GitHub\\Flower_Classifier_Project\\flower_data\\valid\n",
      "    Using test path: \tD:\\GitHub\\Flower_Classifier_Project\\flower_data\\test\n"
     ]
    }
   ],
   "source": [
    "results.data_dir = r'D:\\GitHub\\Flower_Classifier_Project\\flower_data'\n",
    "# setting data directory\n",
    "if results.data_dir == None:\n",
    "    data_dir = input('What is the root path of the data? - default is flower_data ->')\n",
    "    if data_dir == '' or data_dir.lower() == 'default': data_dir = 'flower_data'\n",
    "else:\n",
    "    data_dir = results.data_dir\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print('-\\nModel data folders:')\n",
    "print(\n",
    "'    Using root path: \\t{}\\n\\\n",
    "    Using train path: \\t{}\\n\\\n",
    "    Using valid path: \\t{}\\n\\\n",
    "    Using test path: \\t{}'.format(data_dir, train_dir, valid_dir, test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Your test images have been transformed.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_data_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=means, std=stds)])\n",
    "\n",
    "test_data_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=means, std=stds)])\n",
    "\n",
    "valid_data_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=means, std=stds)])\n",
    "\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_image_datasets = datasets.ImageFolder(train_dir, transform=train_data_transforms)\n",
    "test_image_datasets = datasets.ImageFolder(train_dir, transform=test_data_transforms)\n",
    "valid_image_datasets = datasets.ImageFolder(test_dir, transform=valid_data_transforms)\n",
    "class_to_tensoridx_dict = train_image_datasets.class_to_idx\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_dataloaders = torch.utils.data.DataLoader(train_image_datasets, batch_size=40, shuffle=True)\n",
    "test_dataloaders = torch.utils.data.DataLoader(test_image_datasets, batch_size=40, shuffle=True)\n",
    "valid_dataloaders = torch.utils.data.DataLoader(valid_image_datasets, batch_size=16, shuffle=True)\n",
    "                                           \n",
    "dataloaders = {'train': train_dataloaders, 'test': test_dataloaders, 'valid': valid_dataloaders}\n",
    "                                           \n",
    "print('Great! Your test images have been transformed.')\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "#results.device = 'cuda'\n",
    "def device_validation():\n",
    "    \n",
    "    if results.device == None:\n",
    "        if torch.cuda.is_available():    \n",
    "            device = input('In what device do you want to run this model, cuda or cpu? ->')\n",
    "            if device.lower() in ['cpu', 'cuda']:\n",
    "                print('Thanks! You selected to run the model using the {}.'.format(device))\n",
    "                return device\n",
    "            else:\n",
    "                print('Warning! Wrong input. Choose cuda or cpu.')\n",
    "                return device_validation()\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            print('Sorry! But your device does not support GPU. Note that the training will run faster with a GPU. \\\n",
    "            Please, consider changing to a device with a GPU.')\n",
    "    else:\n",
    "        return results.device\n",
    "device = device_validation()\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "#results.epochs = 1\n",
    "def epoch_validation():\n",
    "    \n",
    "    if results.epochs == None:\n",
    "        try:\n",
    "            epochs = int(input('How many epoch do you want to run? \\\n",
    "            \\nenter int value ->'))\n",
    "            print('Thanks! You have selected to run {} epochs.'.format(epochs))\n",
    "            return epochs\n",
    "        except:\n",
    "            print('Warning! Enter only integer values')   \n",
    "            return epoch_validation()\n",
    "    else:\n",
    "        return results.epochs\n",
    "    \n",
    "epochs = epoch_validation()\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many steps before printing the epoch and loss?         \n",
      "enter int value -> 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks! You have selected to print the epochs and loss on every 40 steps.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "def print_sequence_validation():\n",
    "    try:\n",
    "        print_sequence = int(input('How many steps before printing the epoch and loss? \\\n",
    "        \\nenter int value ->'))\n",
    "        print('Thanks! You have selected to print the epochs and loss on every {} steps.'.format(print_sequence))\n",
    "        return print_sequence\n",
    "    except:\n",
    "        print('Warning! Enter only integer values')\n",
    "        return print_sequence_validation()\n",
    "    \n",
    "print_sequence = print_sequence_validation()  \n",
    "print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "#results.learning_rate = 0.001\n",
    "def learning_rate_validation():\n",
    "    \n",
    "    if results.learning_rate == None:    \n",
    "        try:\n",
    "            learning_rate = float(input('What is the learning rate desired? \\\n",
    "            \\nenter float value ->'))\n",
    "            print('Thanks! You have selected use a learning rate of {:f} steps.'.format(learning_rate))\n",
    "            return learning_rate\n",
    "        except:\n",
    "            print('Warning! Enter only float numbers')\n",
    "            return learning_rate_validation()\n",
    "    else:\n",
    "        return results.learning_rate\n",
    "    \n",
    "learning_rate = learning_rate_validation()\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! You have selected the densenet121 architecture.\n",
      "The model input layer is 1024\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "#results.arch = 'densenet121'\n",
    "def choose_model():\n",
    "    \n",
    "    def set_model_input_name():\n",
    "        if model_selected in ['1', 'densenet121']: \n",
    "            model = models.densenet121(pretrained=True)\n",
    "            input_features = model.classifier.in_features   \n",
    "            model_name = 'densenet121'\n",
    "            print('Great! You have selected the densenet121 architecture.')\n",
    "            print('The model input layer is', input_features)\n",
    "            return model, input_features, model_name\n",
    "        elif model_selected in ['2', 'vgg19_bn']: \n",
    "            model = models.vgg19_bn(pretrained=True)\n",
    "            input_features = model.classifier[0].in_features\n",
    "            model_name = 'vgg19_bn'\n",
    "            print('Great! You have selected the vgg19_bn architecture.')\n",
    "            print('The model input layer is', input_features)\n",
    "            return model, input_features, model_name\n",
    "        else:\n",
    "            print('Wanring! Please select a valid architecture: 1 for densenet121 or 2 for vgg19_bn.')\n",
    "            return choose_model()\n",
    "    \n",
    "    if results.arch == None:           \n",
    "        print('Great! We have two great models to run: 1 for densenet121 or 2 for vgg19_bn')\n",
    "        model_selected = str(input('Which model will you choose, 1 or 2? ->'))\n",
    "        return set_model_input_name()\n",
    "    else:\n",
    "        model_selected = results.arch\n",
    "        return set_model_input_name()\n",
    "\n",
    "model, input_features, model_name = choose_model()   \n",
    "print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_generator(hidden_layer_qty, model_input_features, hidden_layer_inputs, output_dim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    hidden_layer_qty: the number of hidden layers -required\n",
    "    model_input_features: the model imput features comming from the selected model -required\n",
    "    hidden_layer_inputs: the hidden layer imputs in a list [input_int, input_int2] -required\n",
    "    output_dim: the dimensions of the LogSoftmax output -default 1\n",
    "    \n",
    "    returns the model classifier\n",
    "        assign it by using model.classifier = hidden_layer_generator(parameters_here)\n",
    "    \"\"\"\n",
    "    if hidden_layer_qty == len(hidden_layer_inputs):\n",
    "        \n",
    "        # initiating layer list\n",
    "        hidden_layers = [('fc1', nn.Linear(input_features , hidden_layer_inputs[0])), \n",
    "                         ('relu', nn.ReLU()),\n",
    "                         ('dropout', nn.Dropout(p=0.5))]\n",
    "        \n",
    "        # generating hidden layers and output  \n",
    "        for number in range(hidden_layer_qty):\n",
    "            fc = number + 2\n",
    "            layer_name = ('fc%s' % fc)\n",
    "            try:\n",
    "                layer = nn.Linear(hidden_layer_inputs[number], hidden_layer_inputs[number+1])\n",
    "            except:\n",
    "                layer = nn.Linear(hidden_layer_inputs[number], 102)\n",
    "            hidden_layers.append((layer_name, layer))\n",
    "            if number < range(hidden_layer_qty)[-1]:\n",
    "                hidden_layers.append(('relu', nn.ReLU()))\n",
    "                hidden_layers.append(('dropout', nn.Dropout(p=0.5)))\n",
    "            else:\n",
    "                hidden_layers.append(('output', nn.LogSoftmax(dim=output_dim)))\n",
    "\n",
    "    else:\n",
    "        print('The lenght of the list of hidden layers does not equal the quantity of layers.')\n",
    "        \n",
    "    return hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers exceeds input layer of 1024. Please use the command input to enter the hidden layers.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of hidden inputs separated by 1 space             \n",
      "(E.g. 500 300 120) -> 500300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers exceeds input layer of 1024. Please use the command input to enter the hidden layers.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a list of hidden inputs separated by 1 space             \n",
      "(E.g. 500 300 120) -> 500 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "\n",
      "Great! Your classifier is ready:\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc2): Linear(in_features=500, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=102, bias=True)\n",
      "  (output): LogSoftmax()\n",
      ")\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "#results.hidden_units = None\n",
    "def layer_validation():\n",
    "    \n",
    "    def layer_treshold_violation(layer_argument):\n",
    "        if layer_argument[0] >= input_features*.95:\n",
    "            print('Hidden layers exceeds input layer of %s. \\\n",
    "Please use the command input to enter the hidden layers.' % input_features)\n",
    "        return layer_argument[0] >= input_features*.95\n",
    "    \n",
    "    def layer_arguments():\n",
    "        try:\n",
    "            hidden_layer_inputs = input('Enter a list of hidden inputs separated by 1 space \\\n",
    "            \\n(E.g. 500 300 120) ->').split(' ')\n",
    "            hidden_layer_inputs = [int(num) for num in hidden_layer_inputs]\n",
    "            \n",
    "            # hidden layer validation\n",
    "            if layer_treshold_violation(hidden_layer_inputs):\n",
    "                return layer_arguments()\n",
    "            else:\n",
    "                return len(hidden_layer_inputs), hidden_layer_inputs, 1 \n",
    "        except:\n",
    "            print('Warning! Unexpedted input character, please enter integers')\n",
    "            print(\"Let's try that again: \\n\")\n",
    "            #return layer_arguments()\n",
    "\n",
    "    \n",
    "    if results.hidden_units == None:\n",
    "        return layer_arguments()\n",
    "    else:\n",
    "        if layer_treshold_violation(results.hidden_units):\n",
    "            results.hidden_units = None\n",
    "            return layer_arguments()\n",
    "        else:\n",
    "            return len(results.hidden_units), results.hidden_units, 1\n",
    "    \n",
    "# calling function\n",
    "hidden_layer_qty, hidden_layer_inputs, ouput_dim = layer_validation()\n",
    "    \n",
    "hidden_layers = hidden_layer_generator(hidden_layer_qty, \n",
    "                                                input_features, \n",
    "                                                hidden_layer_inputs, \n",
    "                                                ouput_dim)\n",
    "ordered_dict = OrderedDict(hidden_layers)\n",
    "\n",
    "classifier = nn.Sequential(ordered_dict)\n",
    "\n",
    "print('-')\n",
    "print('\\nGreat! Your classifier is ready:')\n",
    "print(classifier)\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickTock:\n",
    "    \"\"\"\n",
    "    Automatic timer. Assign it to a variable and call the stop_clock method.\n",
    "    Returns a string format '0:00:00.000000'\n",
    "    \"\"\"\n",
    "    def __init__(self):        \n",
    "        self.start_time = dt.now()\n",
    "    def stop_clock(self):\n",
    "        td = dt.now() - self.start_time\n",
    "        return ':'.join(str(td).split(':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is now training. :)\n",
      "Epoch: 1/1 -|-  Train Loss: 0.1156 -|-  Test Loss: 4.625 -|-  Test Accuracy: 0.027\n",
      "Epoch: 1/1 -|-  Train Loss: 4.3547 -|-  Test Loss: 3.839 -|-  Test Accuracy: 0.213\n",
      "Epoch: 1/1 -|-  Train Loss: 3.5342 -|-  Test Loss: 2.584 -|-  Test Accuracy: 0.417\n",
      "Epoch: 1/1 -|-  Train Loss: 2.7043 -|-  Test Loss: 1.776 -|-  Test Accuracy: 0.572\n",
      "Epoch: 1/1 -|-  Train Loss: 2.2217 -|-  Test Loss: 1.328 -|-  Test Accuracy: 0.690\n",
      "Training time: 0:09:13.611189\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "print('The model is now training. :)')\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = classifier\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "timer = TickTock()\n",
    "\n",
    "for e in range(epochs):    \n",
    "    running_loss = 0\n",
    "    for steps, (images, labels) in enumerate(dataloaders['train']):\n",
    "        model.train()\n",
    "        \n",
    "        # move images and labels to device selected\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if steps % print_sequence == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, dataloaders['test'], criterion)\n",
    "            \n",
    "            \n",
    "            print(\"Epoch: {}/{} -|- \".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.4f} -|- \".format(running_loss/print_sequence),\n",
    "                  \"Test Loss: {:.3f} -|- \".format(test_loss/len(dataloaders['test'])),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(dataloaders['test'])))\n",
    "            running_loss = 0   \n",
    "\n",
    "time_delta = timer.stop_clock()\n",
    "print('Training time:', time_delta)\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.save_dir = r'D:\\GitHub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.save_dir:\n",
    "    checkpoint_path = results.save_dir + '\\\\checkpoint.pth'\n",
    "else:\n",
    "    checkpoint_path = 'checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved with class_to_idx, classifier, model, and state_dict\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "model.class_to_idx = class_to_tensoridx_dict\n",
    "checkpoint = {'class_to_idx': model.class_to_idx, \n",
    "              'classifier': model.classifier, \n",
    "              'model': model_name, \n",
    "              'state_dict': model.state_dict()} \n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "print('Checkpoint saved with {}'.format(', '.join(list(checkpoint.keys())[:-1])+', and '+list(checkpoint.keys())[-1] ))\n",
    "print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Accuracy of Model with Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are now checking the accuracy of the model. :)\n",
      "Training is done.\n",
      "Here is the accuracy of the network on test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "print('We are now checking the accuracy of the model. :)')\n",
    "correct = 0\n",
    "total = 0\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in test_dataloaders:\n",
    "        # move images and labels to device selected\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Training is done.')\n",
    "print('Here is the accuracy of the network on test images: %d %%' %\n",
    "     (100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
